{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doğrusal Bağlanım (Linear Regression)\n",
    "yazan Marc Deisenroth, çeviren Utku Karaca\n",
    "\n",
    "Doğrusal bağlanım problemi:\n",
    "$$\n",
    "y = \\boldsymbol x^T\\boldsymbol\\theta + \\epsilon\\,,\\quad \\epsilon \\sim \\mathcal N(0, \\sigma^2)\n",
    "$$\n",
    "\n",
    "$\\boldsymbol x\\in\\mathbb{R}^D$ girdiler ve $y\\in\\mathbb{R}$ gürültülü gözlemler. Parametre vektörü $\\boldsymbol\\theta\\in\\mathbb{R}^D$ ise fonksiyonumuzu belirleyen vektör.\n",
    "\n",
    "Eğitim kümesi $(\\boldsymbol x_n, y_n)$, $n=1,\\ldots, N$, sırasıyla, kısa gösterim olarak $\\mathcal X = \\{\\boldsymbol x_1, \\ldots, \\boldsymbol x_N\\}$ ve eşlenik eğitim hedefleri $\\mathcal Y = \\{y_1, \\ldots, y_N\\}$.\n",
    "\n",
    "Bu eğitimde amacımız iyi $\\boldsymbol\\theta$ parametrelerine ulaşmak.\n",
    "\n",
    "Gerekli paketler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eğitim kümesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim kümesinin tanımlanması\n",
    "X = np.array([-3, -1, 0, 1, 3]).reshape(-1,1) # 5x1 vektör, N=5, D=1\n",
    "y = np.array([-1.2, -0.7, 0.14, 0.67, 1.67]).reshape(-1,1) # 5x1 vektör\n",
    "\n",
    "# Eğitim kümesinin grafik üzerinde gösterilmesi\n",
    "plt.figure()\n",
    "plt.plot(X, y, '+', markersize=10)\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. En Büyük Olabilirlik (Maximum Likelihood) \n",
    "$\\boldsymbol\\theta$ parametresinin en büyük olabilirlik kestirimi ile başlayacağız. Olabilirliği en çoklayan $\\boldsymbol\\theta^{\\mathrm{ML}}$ parametrelerini bulacağız. \n",
    "\n",
    "Olabilirlik fonksiyonu:\n",
    "$$\n",
    "p(\\mathcal Y | \\mathcal X, \\boldsymbol\\theta) = \\prod_{n=1}^N p(y_n | \\boldsymbol x_n, \\boldsymbol\\theta)\\,.\n",
    "$$\n",
    "Olabilirlik fonksiyonunu en çoklayan analitik ifade:\n",
    "$$\n",
    "\\boldsymbol\\theta^{\\text{ML}} = (\\boldsymbol X^T\\boldsymbol X)^{-1}\\boldsymbol X^T\\boldsymbol y\\in\\mathbb{R}^D\\,,\n",
    "$$\n",
    " \n",
    "$$\n",
    "\\boldsymbol X = [\\boldsymbol x_1, \\ldots, \\boldsymbol x_N]^T\\in\\mathbb{R}^{N\\times D}\\,,\\quad \\boldsymbol y = [y_1, \\ldots, y_N]^T \\in\\mathbb{R}^N\\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_lik_kestirimi(X, y):\n",
    "    # X: N x D eğitim kümesi matrisi\n",
    "    # y: N x 1 eğitim hedefler/gözlemler vektörü\n",
    "    # dön: en büyük olabilirlik parametreleri maximum likelihood parameters (D x 1)\n",
    "    \n",
    "    theta_ml = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "    return theta_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en büyük olabilirlik kestirimi\n",
    "theta_ml = max_lik_kestirimi(X, y)\n",
    "print(theta_ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En büyük olabilirlik kestirimini kullanarak tahmin yapma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kestirim_ile_tahmin(Xtest, theta):\n",
    "    \n",
    "    # Xtest: K x D test kümesi matrisi\n",
    "    # theta: D x 1 parametre vektörü\n",
    "    # dön: f(Xtest) tahmini; K x 1 vektör \n",
    "    \n",
    "    tahmin = Xtest.dot(theta)\n",
    "    \n",
    "    return tahmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sonuçlar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test kümesi tanımlanması\n",
    "#     100 x 1 vektör\n",
    "Xtest = np.linspace(-5,5,100).reshape(-1,1)\n",
    "\n",
    "# En büyük olabilirlik kestirici (Maximum Likelihood Estimator)\n",
    "# ile test noktalarındaki fonksiyon değerini tahmin etme\n",
    "ml_tahmini = kestirim_ile_tahmin(Xtest, theta_ml)\n",
    "\n",
    "# grafik\n",
    "plt.figure()\n",
    "plt.plot(X, y, '+', markersize=10)\n",
    "plt.plot(Xtest, ml_tahmini)\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Farklı bir eğitim kümesine bakalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_yeni = y + 2.0\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(X, y_yeni, '+', markersize=10)\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en büyük olabilirlik kestirimleri\n",
    "theta_ml = max_lik_kestirimi(X, y_yeni)\n",
    "print(theta_ml)\n",
    "\n",
    "# test kümesinin tanımlanması\n",
    "Xtest = np.linspace(-5,5,100).reshape(-1,1)\n",
    "\n",
    "# En büyük olabilirlik kestirici (Maximum Likelihood Estimator)\n",
    "# ile test noktalarındaki fonksiyon değerini tahmin etme\n",
    "ml_tahmini = kestirim_ile_tahmin(Xtest, theta_ml)\n",
    "\n",
    "# plot\n",
    "plt.figure()\n",
    "plt.plot(X, y_yeni, '+', markersize=10)\n",
    "plt.plot(Xtest, ml_tahmini)\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soru:\n",
    "1. Yapılan son kestirim iyi değil: Turuncu çizgi gözlem noktalarından çok uzak. Neden?\n",
    "2. Bu problemi nasıl giderebiliriz?\n",
    "\n",
    "Yeni bir doğrusal bağlanım modeli: Daha esnek model. \n",
    "$$\n",
    "y = \\theta_0 + \\boldsymbol x^T \\boldsymbol\\theta_1 + \\epsilon\\,,\\quad \\epsilon\\sim\\mathcal N(0,\\sigma^2)\n",
    "$$\n",
    "İlk modele bir yanlılık parametresi ekledik.\n",
    "#### Question:\n",
    "1. Bu yanlılık parametresinin etkisi nedir? Nasıl bir esneklik sağlayacaktır?\n",
    "\n",
    "Yanlılık parametresini hesaba katarak genişletilmiş girdi vektörümüz:\n",
    "$\\boldsymbol x_{\\text{aug}} = \\begin{bmatrix}1\\\\\\boldsymbol x\\end{bmatrix}$. Yeni modelimiz:  \n",
    "$$\n",
    "y = \\boldsymbol x_{\\text{aug}}^T\\boldsymbol\\theta_{\\text{aug}} + \\epsilon\\,,\\quad \\boldsymbol\\theta_{\\text{aug}} = \\begin{bmatrix}\n",
    "\\theta_0\\\\\n",
    "\\boldsymbol\\theta_1\n",
    "\\end{bmatrix}\\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D = X.shape\n",
    "# genişletilmiş eğitim kümesi matrisi: N x (D+1)\n",
    "X_gen = np.hstack([np.ones((N,1)), X])\n",
    "# yeni theta vektörü: (D+1) x 1\n",
    "theta_gen = np.zeros((D+1, 1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeni modelimiz için en büyük olabilirlik kestirici:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_lik_kestirici_gen(X_gen, y):\n",
    "    \n",
    "    theta_gen_ml = max_lik_kestirimi(X_gen, y)\n",
    "    \n",
    "    return theta_gen_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_gen_ml = max_lik_kestirici_gen(X_gen, y_yeni)\n",
    "print(theta_gen_ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeni tahminler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test kümesi yaratılması \n",
    "# (girdileri 1'ler ile genişletmemiz gerekiyor)\n",
    "Xtest_gen = np.hstack([np.ones((Xtest.shape[0],1)), Xtest])\n",
    "\n",
    "# En büyük olabilirlik kestirici (Maximum Likelihood Estimator)\n",
    "# ile test noktalarındaki fonksiyon değerini tahmin etme\n",
    "ml_tahmin = kestirim_ile_tahmin(Xtest_gen, theta_gen_ml)\n",
    "\n",
    "# plot\n",
    "plt.figure()\n",
    "plt.plot(X, y_yeni, '+', markersize=10)\n",
    "plt.plot(Xtest, ml_tahmin)\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doğrusal olmayan öznitelikler (Nonlinear Features)\n",
    "Doğrusal bağlanım doğrusal olmayan fonksiyoları tahmin etmede de kullanılabilir. Önemli olan $\\boldsymbol\\theta$ parametresinin doğrusal olarak uygulanmasıdır. $\\boldsymbol x$ doğrusal olmayan girdiler içerebilir.\n",
    "\n",
    "Doğrusal bağlanım ile öğrenebileceğimiz fonksiyon gösterimi:\n",
    "$$\n",
    "f(\\boldsymbol x, \\boldsymbol\\theta) = \\sum_{k = 1}^K \\theta_k \\phi_k(\\boldsymbol x)\\,,\n",
    "$$\n",
    "Öznitelikler ($\\phi_k(\\boldsymbol x)$) $\\boldsymbol x$'lerin (muhtemelen doğrusal olmayan) dönüşümünü göstermektedir.\n",
    "\n",
    "Örnek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([10.05, 1.5, -1.234, 0.02, 8.03]).reshape(-1,1)\n",
    "plt.figure()\n",
    "plt.plot(X, y, '+')\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polinomsal Bağlanım (Polynomial Regression)\n",
    "Polinomları doğrusal bağlanım kullanarak tahminleyebiliriz çünkü bir polinomu $K$ dereceli yazabiliriz:\n",
    "\n",
    "$$\\sum_{k=0}^K \\theta_k x^k = \\boldsymbol \\phi(x)^T\\boldsymbol\\theta\\,,\\quad\n",
    "\\boldsymbol\\phi(x)= \n",
    "\\begin{bmatrix}\n",
    "x^0\\\\\n",
    "x^1\\\\\n",
    "\\vdots\\\\\n",
    "x^K\n",
    "\\end{bmatrix}\\in\\mathbb{R}^{K+1}\\,.\n",
    "$$\n",
    "$\\boldsymbol\\phi(x)$:$x\\in\\mathbb{R}$'lerin doğrusal olmayan öznitelik dönüşümü.\n",
    "\n",
    "Bütün öznitelik dönüşümlerini bir matris altında toplayabiliriz:\n",
    "$$\n",
    "\\boldsymbol\\Phi = \\begin{bmatrix}\n",
    "\\boldsymbol\\phi(x_1) & \\boldsymbol\\phi(x_2) & \\cdots & \\boldsymbol\\phi(x_n)\n",
    "\\end{bmatrix}^T \\in\\mathbb{R}^{N\\times K+1}\n",
    "$$\n",
    "\n",
    "$\\boldsymbol\\Phi$ öznitelik matrisi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poli_oznitelikleri(X, K):\n",
    "    \n",
    "    # X: girdiler N x 1\n",
    "    # K: polinom derecesi \n",
    "    # öznitelik matrisi Phi'yi hesaplar (N x (K+1))\n",
    "    \n",
    "    X = X.flatten()\n",
    "    N = X.shape[0]\n",
    "    \n",
    "    # Phi matrisinin yaratılması\n",
    "    Phi = np.zeros((N, K+1))\n",
    "    \n",
    "    # Öznitelik matrisinin hesaplanması\n",
    "    for k in range(K+1):\n",
    "        Phi[:,k] = X**k #X^k\n",
    "    return Phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Öznitelik matrisini kullanarak en büyük olabilirlik kestiricisini aşağıdaki gibi hesaplayabiliriz:\n",
    "$$\n",
    "\\boldsymbol \\theta^\\text{ML} = (\\boldsymbol\\Phi^T\\boldsymbol\\Phi)^{-1}\\boldsymbol\\Phi^T\\boldsymbol y\n",
    "$$\n",
    "\n",
    "Genellikle sayısal kararlılık için $\\boldsymbol\\Phi^T\\boldsymbol\\Phi$ terimine küçük diyagonal seğirme ($\\kappa>0$) ekliyoruz. Bu sayede önemli bir sıkıntı yaşamadan tersini alabiliyoruz. Böylece en büyük olabilirlik kestirimi:\n",
    "$$\n",
    "\\boldsymbol \\theta^\\text{ML} = (\\boldsymbol\\Phi^T\\boldsymbol\\Phi + \\kappa\\boldsymbol I)^{-1}\\boldsymbol\\Phi^T\\boldsymbol y\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dog_olm_oznitelik_ml(Phi, y):\n",
    "    # Phi: eğitim kümesi için öznitelik matrisi, N x D\n",
    "    # y: eğitim kümesi hedefleri, N x 1\n",
    "    # dön: en büyük olabilirlik kestiricisi theta_ml, D x 1\n",
    "    \n",
    "    kappa = 1e-08 # seğirme terimi; sayısal kararlılık için\n",
    "    \n",
    "    D = Phi.shape[1]  \n",
    "    \n",
    "    # en büyük olabilirlik kestiricisi\n",
    "    Pt = Phi.T.dot(y) # Phi^T*y\n",
    "    PP = Phi.T.dot(Phi) + kappa*np.eye(D) # Phi^T*Phi + kappa*I\n",
    "        \n",
    "    # en büyük olabilirlik kestiricisi\n",
    "    C = scipy.linalg.cho_factor(PP)\n",
    "    theta_ml = scipy.linalg.cho_solve(C, Pt) # inv(Phi^T*Phi + kappa*I)*Phi^T*y \n",
    "    \n",
    "    return theta_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eldekiler:\n",
    "* Öznitelik matrisi\n",
    "* Polinomsal bağlanım için en büyük olabilirlik kestiricisi\n",
    "\n",
    "Test seti $\\boldsymbol X_{\\text{test}}\\in\\mathbb{R}$ tahmini yapabilmek için $\\boldsymbol X_{\\text{test}}$'in öznitelik dönüşümlerini yapmamız gerekiyor. \n",
    "\n",
    "$$\\boldsymbol\\Phi_{\\text{test}}= \\boldsymbol\\phi(\\boldsymbol X_{\\text{test}})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 2 # uyumlamak istediğimiz polinom derecesi\n",
    "Phi = poli_oznitelikleri(X, K) # öznitelik matrisi, N x (K+1)\n",
    "\n",
    "theta_ml = dog_olm_oznitelik_ml(Phi, y) # en büyük olabilirlik kestiricisi\n",
    "\n",
    "# test veri kümesinin yaratılması\n",
    "Xtest = np.linspace(-4,4,100).reshape(-1,1)\n",
    "\n",
    "# test girdileri için öznitelik matrisi\n",
    "Phi_test = poli_oznitelikleri(Xtest, K)\n",
    "\n",
    "y_tahmin = Phi_test.dot(theta_ml) # tahmin edilen y değerleri\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(X, y, '+')\n",
    "plt.plot(Xtest, y_tahmin)\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\");\n",
    "\n",
    "print(theta_ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Kalitesini Değerlendirme\n",
    "Yeni bir veri kümesi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):   \n",
    "    return np.cos(x) + 0.2*np.random.normal(size=(x.shape))\n",
    "\n",
    "X = np.linspace(-4,4,20).reshape(-1,1)\n",
    "y = f(X)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(X, y, '+')\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polinomsal bağlanım kodunu kullanarak bu veri setini tahmin edelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 1 # uyumlamak istediğimiz polinom derecesi\n",
    "\n",
    "Phi = poli_oznitelikleri(X, K) # öznitelik matrisi, N x (K+1)\n",
    "\n",
    "theta_ml = dog_olm_oznitelik_ml(Phi, y) # en büyük olabilirlik kestiricisi\n",
    "\n",
    "# test kümesi yaratılması\n",
    "Xtest = np.linspace(-5,5,100).reshape(-1,1)\n",
    "ytest = f(Xtest) # gerçek y değerleri\n",
    "\n",
    "# test girdileri için öznitelik matrisi\n",
    "Phi_test = poli_oznitelikleri(Xtest, K)\n",
    "\n",
    "y_tahmin = Phi_test.dot(theta_ml) # tahmini y değerleri\n",
    "\n",
    "# plot\n",
    "plt.figure()\n",
    "plt.plot(X, y, '+')\n",
    "plt.plot(Xtest, y_tahmin)\n",
    "plt.plot(Xtest, ytest)\n",
    "plt.legend([\"gözlem\", \"kestirim\", \"gerçek gözlem (Test)\"])\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yöntemli bir şekilde model kalitesini değerlendirebilir miyiz? \n",
    "\n",
    "Ortalama karesel hata (OKH): \n",
    "$$\n",
    "\\text{OKH} = \\sqrt{\\frac{1}{N}\\sum_{n=1}^N(y_n - y_n^\\text{pred})^2}\n",
    "$$\n",
    "\n",
    "Fonksiyonu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OKH(y, y_tahmin):\n",
    "    okh = np.sqrt(np.mean((y-y_tahmin)**2))\n",
    "    return okh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Farklı polinom dereceleri için OKH hesaplanması:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_max = 20\n",
    "okh_egitim = np.zeros((K_max+1,))\n",
    "\n",
    "for k in range(K_max+1):\n",
    "    # öznitelik matrisi\n",
    "    Phi = poli_oznitelikleri(X, k)\n",
    "    \n",
    "    # en büyük olabilirlik kestirici (maximum likelihood estimate)\n",
    "    theta_ml = dog_olm_oznitelik_ml(Phi, y)\n",
    "    \n",
    "    # eğitim kümesi y değerlerinin tahmini\n",
    "    y_tahmin_egitim = Phi.dot(theta_ml)\n",
    "    \n",
    "    # RMSE on training set\n",
    "    okh_egitim[k] = OKH(y, y_tahmin_egitim)\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.plot(okh_egitim)\n",
    "plt.xlabel(\"polinom derecesi\")\n",
    "plt.ylabel(\"OKH\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eğitim kümesinde en iyi sonucu veren polinom derecesinin performansını test kümesinde inceleyelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(X, y, '+')\n",
    "\n",
    "# öznitelik matrisi\n",
    "Phi = poli_oznitelikleri(X, 5)\n",
    "\n",
    "# en büyük olabilirlik kestirici (maximum likelihood estimate)\n",
    "theta_ml = dog_olm_oznitelik_ml(Phi, y)   \n",
    "\n",
    "# test kümesi için y değerlerinin tahmini\n",
    "Phi_test = poli_oznitelikleri(Xtest, 5)\n",
    "\n",
    "y_tahmin_test = Phi_test.dot(theta_ml)\n",
    "\n",
    "plt.plot(Xtest, y_tahmin_test) \n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "plt.legend([\"veri\", \"en iyi en büyük olabilirlik (maximum likelihood fit)\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin gerçek performansını görmek için eğitim kümesi üzerindeki OKH yanıltıcı olabilir. Bu sebeple test kümesi üzerinde en düşük OKH değerini veren dereceyi seçmeliyiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_max = 20\n",
    "okh_egitim = np.zeros((K_max+1,))\n",
    "okh_test = np.zeros((K_max+1,))\n",
    "\n",
    "for k in range(K_max+1):\n",
    "    \n",
    "    # öznitelik matrisi\n",
    "    Phi = poli_oznitelikleri(X, k)\n",
    "    \n",
    "    # en büyük olabilirlik kestirici (maximum likelihood estimate)\n",
    "    theta_ml = dog_olm_oznitelik_ml(Phi, y)\n",
    "    \n",
    "    # eğitim kümesi y değer tahminleri\n",
    "    y_tahmin_egitim = Phi.dot(theta_ml)\n",
    "    \n",
    "    # eğitim kümesi OKH değeri\n",
    "    okh_egitim[k] = OKH(y, y_tahmin_egitim)    \n",
    "    \n",
    "    # test kümesi için öznitelik matrisi\n",
    "    Phi_test = poli_oznitelikleri(Xtest, k)\n",
    "    \n",
    "    # test kümesi tahmini\n",
    "    y_tahmin_test = Phi_test.dot(theta_ml)\n",
    "    \n",
    "    # test kümesi OKH değeri on test set\n",
    "    okh_test[k] = OKH(ytest, y_tahmin_test)\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.semilogy(okh_egitim) # logaritmik ölçekte OKH \n",
    "plt.semilogy(okh_test) # logaritmik ölçekte OKH \n",
    "plt.xlabel(\"polinom derecesi\")\n",
    "plt.ylabel(\"OKH\")\n",
    "plt.legend([\"eğitim kümesi\", \"test kümesi\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En iyi polinom derecesi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(X, y, '+')\n",
    "k = 5\n",
    "# öznitelik matrisi\n",
    "Phi = poli_oznitelikleri(X, k)\n",
    "\n",
    "# en büyük olabilirlik kestirici (maximum likelihood estimate)\n",
    "theta_ml = dog_olm_oznitelik_ml(Phi, y)   \n",
    "\n",
    "# test kümesi için öznitelik matrisi\n",
    "Phi_test = poli_oznitelikleri(Xtest, k)\n",
    "\n",
    "y_tahmin_test = Phi_test.dot(theta_ml)\n",
    "\n",
    "plt.plot(Xtest, y_tahmin_test) \n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "plt.legend([\"veri\", \"en büyük olabilirlik kestirici (maximum likelihood estimate)\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. En Büyük Posteriyori Kestirim (Maximum A Posteriori Estimation, MAP Estimation)\n",
    "Model:\n",
    "$$\n",
    "y = \\boldsymbol\\phi(\\boldsymbol x)^T\\boldsymbol\\theta + \\epsilon\\,,\\quad \\epsilon\\sim\\mathcal N(0,\\sigma^2)\\,.\n",
    "$$\n",
    "Gürültü varyansının ($\\sigma^2$) bildiğimizi varsayıyoruz.\n",
    "\n",
    "Olabilirliği en büyüklemek yerine parametrelerin ($\\boldsymbol\\theta$) sonsal posteriyori dağılımını en büyükleyebiliriz:\n",
    "$$\n",
    "p(\\boldsymbol\\theta|\\mathcal X, \\mathcal Y) = \\frac{\\overbrace{p(\\mathcal Y|\\mathcal X, \\boldsymbol\\theta)}^{\\text{olabilirlik (likelihood)}}\\overbrace{p(\\boldsymbol\\theta)}^{\\text{önsel (prior)}}}{\\underbrace{p(\\mathcal Y|\\mathcal X)}_{\\text{kanıt(evidence)}}}\n",
    "$$\n",
    "Önsel olasılık parametresinin ($p(\\boldsymbol\\theta)$) amacı parametrelerin ekstrem değerler almasını engellemektir, örneğin aşırı uyumlama (overfitting). Önsellik \"makul\" bir parametre değerler aralığı belirlememizi sağlar. Genellikle Gauss (ortalaması $\\boldsymbol 0$ ve varyansı $\\alpha^2$) önselini tercih ediyoruz $\\mathcal N(\\boldsymbol 0, \\alpha^2\\boldsymbol I)$.\n",
    "\n",
    "Parametrelerin MAP kestirimi:\n",
    "$$\n",
    "\\boldsymbol\\theta^{\\text{MAP}} = (\\boldsymbol\\Phi^T\\boldsymbol\\Phi + \\frac{\\sigma^2}{\\alpha^2}\\boldsymbol I)^{-1}\\boldsymbol\\Phi^T\\boldsymbol y\n",
    "$$\n",
    "$\\sigma^2$: gürültü varyansı."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_kestirim_poli(Phi, y, sigma, alpha):\n",
    "    # Phi: eğitim kümesi, N x D\n",
    "    # y: eğitim hedef değerleri, D x 1\n",
    "    # sigma: gürültünün standart sapma \n",
    "    # alpha: parametre önselliğinin standart sapması\n",
    "    # dön: MAP kestirimi theta_map, Size of D x 1\n",
    "    \n",
    "    D = Phi.shape[1] \n",
    "    \n",
    "    PP = Phi.T.dot(Phi) + (sigma/alpha)**2 * np.eye(D)\n",
    "    theta_map = scipy.linalg.solve(PP, Phi.T.dot(y))\n",
    "    \n",
    "    return theta_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tahmin etmeye çalıştığımız fonksiyon\n",
    "def g(x, sigma):\n",
    "    p = np.hstack([x**0, x**1, np.sin(x)])\n",
    "    w = np.array([-1.0, 0.1, 1.0]).reshape(-1,1)\n",
    "    return p.dot(w) + sigma*np.random.normal(size=x.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veri yaratımı\n",
    "sigma = 1.0 # gürültü standart sapması\n",
    "alpha = 1.0 # parametre önselliğinin standart sapması\n",
    "N = 20\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = (np.random.rand(N)*10.0 - 5.0).reshape(-1,1)\n",
    "y = g(X, sigma) # eğitim kümesi hedef değerleri\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(X, y, '+')\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP estimate kestirimleri\n",
    "K = 8 # polinom derecesi   \n",
    "\n",
    "# öznitelik matrisi\n",
    "Phi = poli_oznitelikleri(X, K)\n",
    "\n",
    "theta_map = map_kestirim_poli(Phi, y, sigma, alpha)\n",
    "\n",
    "# en büyük olabilirlik kestirimi (maximum likelihood estimate)\n",
    "theta_ml = dog_olm_oznitelik_ml(Phi, y)\n",
    "\n",
    "Xtest = np.linspace(-5,5,100).reshape(-1,1)\n",
    "ytest = g(Xtest, sigma)\n",
    "\n",
    "Phi_test = poli_oznitelikleri(Xtest, K)\n",
    "y_tahmin_map = Phi_test.dot(theta_map)\n",
    "\n",
    "y_tahmin_mle = Phi_test.dot(theta_ml)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(X, y, '+')\n",
    "plt.plot(Xtest, y_tahmin_map)\n",
    "plt.plot(Xtest, g(Xtest, 0))\n",
    "plt.plot(Xtest, y_tahmin_mle)\n",
    "\n",
    "plt.legend([\"veri\", \"map tahmini\", \"gerçek fonksiyon\", \"en büyük olabilirlik\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.hstack([theta_ml, theta_map]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Farklı polinom dereceleri için OKH hesaplanması: MAP kestirimi en büyük olabilirlikte karşılaştığımız aşırı uyumlama için bir çözüm mü?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_max = 12 # deneyeceğimiz en büyük polinom derecesi\n",
    "\n",
    "okh_mle = np.zeros((K_max+1,))\n",
    "okh_map = np.zeros((K_max+1,))\n",
    "\n",
    "for k in range(K_max+1):\n",
    "    \n",
    "    # öznitelik matrisi\n",
    "    Phi = poli_oznitelikleri(X, k)\n",
    "    \n",
    "    # en büyük olabilirlik kestirimi (maximum likelihood estimate)\n",
    "    theta_ml = dog_olm_oznitelik_ml(Phi, y)\n",
    "    \n",
    "    # test kümesi için öznitelik matrisi\n",
    "    Phi_test = poli_oznitelikleri(Xtest, k)\n",
    "    \n",
    "    # test noktalarında fonsiyon değerini tahmin etme\n",
    "    # (en büyük olabilirlik - maximum likelihood)\n",
    "    y_tahmin_test_mle = Phi_test.dot(theta_ml)\n",
    "    \n",
    "    # test kümesi OKH değeri (en büyük olabilirlik - maximum likelihood)\n",
    "    okh_mle[k] = OKH(ytest, y_tahmin_test_mle)\n",
    "    \n",
    "    # MAP kestirimi\n",
    "    theta_map = map_kestirim_poli(Phi, y, sigma, alpha)\n",
    "\n",
    "    # öznitelik matrisi\n",
    "    Phi_test = poli_oznitelikleri(Xtest, k)\n",
    "    \n",
    "    # test noktalarında fonsiyon değerini tahmin etme (MAP)\n",
    "    y_tahmin_test_map = Phi_test.dot(theta_map)\n",
    "    \n",
    "    # test kümesi OKH değeri (MAP)\n",
    "    okh_map[k] = OKH(ytest, y_tahmin_test_map)\n",
    "    \n",
    "plt.figure()\n",
    "plt.semilogy(okh_mle) # logaritmik ölçekte OKH \n",
    "plt.semilogy(okh_map) # logaritmik ölçekte OKH \n",
    "plt.xlabel(\"polinom derecesi\")\n",
    "plt.ylabel(\"OKH\")\n",
    "plt.legend([\"En Büyük Olabilirlik (Maximum likelihood)\", \"MAP\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bayesyen Doğrusal Bağlanım (Bayesian Linear Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test kümesi\n",
    "Ntest = 200\n",
    "Xtest = np.linspace(-5, 5, Ntest).reshape(-1,1) # test inputs\n",
    "\n",
    "onsel_var = 2.0 # parametre önselliğinin varyansı (alpha^2). Bilindiği varsayılıyor.\n",
    "gurultu_var = 1.0 # gürültü varyansı (sigma^2). Bilindiği varsayılıyor.\n",
    "\n",
    "pol_der = 3 # polinom derecesi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametre önselliği varsayımı: $p(\\boldsymbol\\theta) = \\mathcal N (\\boldsymbol 0, \\alpha^2\\boldsymbol I)$. Her bir test girdisi $\\boldsymbol x_*$ için, elde ettiğimiz önsel ortalama: \n",
    "$$\n",
    "E[f(\\boldsymbol x_*)] = 0\n",
    "$$\n",
    "ve önsel (marjinal) varyans (gürültüyü yoksayarak)\n",
    "$$\n",
    "V[f(\\boldsymbol x_*)] = \\alpha^2\\boldsymbol\\phi(\\boldsymbol x_*) \\boldsymbol\\phi(\\boldsymbol x_*)^\\top\n",
    "$$\n",
    "$\\boldsymbol\\phi(\\cdot)$: öznitelik eşlemi (feature map)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test kümesi öznitelik matrisinin hesaplanması\n",
    "Phi_test = poli_oznitelikleri(Xtest, pol_der) # özniteli matrisi, N x (pol_der+1)\n",
    "\n",
    "# test girdiler (marjinal) önselliğinin hesaplanması\n",
    "# önsel ortalaması\n",
    "onsel_ortalama = np.zeros((Ntest,1))\n",
    "\n",
    "# önsel varyansı\n",
    "ful_kovaryans = Phi_test.dot(Phi_test.T) * onsel_var # bütün fonksiyon değerler kovaryans matrisi, N x N\n",
    "onsel_marjinal_var =  np.diag(ful_kovaryans)\n",
    "\n",
    "# Let us visualize the prior over functions\n",
    "plt.figure()\n",
    "plt.plot(Xtest, onsel_ortalama, color=\"k\")\n",
    "\n",
    "guven_sinir1 = np.sqrt(onsel_marjinal_var).flatten()\n",
    "guven_sinir2 = 2.0*np.sqrt(onsel_marjinal_var).flatten()\n",
    "guven_sinir3 = 2.0*np.sqrt(onsel_marjinal_var + gurultu_var).flatten()\n",
    "plt.fill_between(Xtest.flatten(), onsel_ortalama.flatten() + guven_sinir1, \n",
    "             onsel_ortalama.flatten() - guven_sinir1, alpha = 0.1, color=\"k\")\n",
    "plt.fill_between(Xtest.flatten(), onsel_ortalama.flatten() + guven_sinir2, \n",
    "                 onsel_ortalama.flatten() - guven_sinir2, alpha = 0.1, color=\"k\")\n",
    "plt.fill_between(Xtest.flatten(), onsel_ortalama.flatten() + guven_sinir3, \n",
    "                 onsel_ortalama.flatten() - guven_sinir3, alpha = 0.1, color=\"k\")\n",
    "\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.title(\"Prior over functions\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use this prior distribution and sample functions from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# önselden örnekler\n",
    "ornek_sayisi = 10\n",
    "\n",
    "# parametre önselinden örneklenen rasgele ağırlıklar yaratmamız gerekiyor\n",
    "rasgele_agirlik = np.random.normal(size=(pol_der+1,ornek_sayisi), scale=np.sqrt(onsel_var))\n",
    "\n",
    "# Now, we compute the induced random functions, evaluated at the test input locations\n",
    "# Every function sample is given as f_i = Phi * theta_i, \n",
    "# where theta_i is a sample from the parameter prior\n",
    "\n",
    "ornek_fonksiyon = Phi_test.dot(rasgele_agirlik)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(Xtest, ornek_fonksiyon, color=\"r\")\n",
    "plt.title(\"Ölcüle göre olası fonsiyonlar\")\n",
    "print(\"Örneklenen bütün fonsiyonlar \"+str(pol_der)+\". dereceden fonsiyonlardır.\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eğitim gözlemlerini $\\boldsymbol x_1, \\dotsc, \\boldsymbol x_N$ bir matris içerisinde toplama: $\\boldsymbol X = [\\boldsymbol x_1, \\dotsc, \\boldsymbol x_N]^\\top\\in\\mathbb{R}^{N\\times D}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "X = np.random.uniform(high=5, low=-5, size=(N,1)) # eğitim kümesi, N x 1\n",
    "y = g(X, np.sqrt(gurultu_var)) # eğitim hedef değerleri, N x 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteriyor hesaplaması:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poliUydur(X, y, K, onsel_var, gurultu_var):\n",
    "    # X: eğitim kümesi, N x D\n",
    "    # y: eğitim hedef değerleri, N x 1\n",
    "    # K: polinom derecesi\n",
    "    # onsel_var: parametre dağılımının önsel varyansı\n",
    "    # sigma: gürültü varyansı\n",
    "    \n",
    "    segirme = 1e-08 # # seğirme terimi; sayısal kararlılık için\n",
    "    \n",
    "    Phi = poli_oznitelikleri(X, K) # öznitelik matrisi, N x (K+1) \n",
    "    \n",
    "    # en büyük olabilirlik kestirimi hesaplaması\n",
    "    Pt = Phi.T.dot(y) # Phi*y, size (K+1,1)\n",
    "    PP = Phi.T.dot(Phi) + segirme*np.eye(K+1) #(K+1, K+1)\n",
    "    C = scipy.linalg.cho_factor(PP)\n",
    "    # en büyük olabilirlik kestirimi (maximum likelihood estimate)\n",
    "    theta_ml = scipy.linalg.cho_solve(C, Pt) # inv(Phi^T*Phi)*Phi^T*y, size (K+1,1)\n",
    "    \n",
    "#     theta_ml = scipy.linalg.solve(PP, Pt) # inv(Phi^T*Phi)*Phi^T*y, size (K+1,1)\n",
    "    \n",
    "    # MAP kestirimi\n",
    "    theta_map = scipy.linalg.solve(PP + gurultu_var/onsel_var*np.eye(K+1), Pt)\n",
    "    \n",
    "    # parametre posteriyoru\n",
    "    iSN = (np.eye(K+1)/onsel_var + PP/gurultu_var) # posteriyor hassaslığı\n",
    "    SN = scipy.linalg.pinv(gurultu_var*np.eye(K+1)/onsel_var + PP)*gurultu_var  # posteriyor kovaryansı\n",
    "    mN = scipy.linalg.solve(iSN, Pt/gurultu_var) # posteriyor ortalaması\n",
    "    \n",
    "    return (theta_ml, theta_map, mN, SN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_ml, theta_map, theta_ortalama, theta_var = poliUydur(X, y, pol_der, alpha, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 farklı kestiricilerden kestirimler:\n",
    "\\begin{align}\n",
    "&\\text{En Büyün Olabilirlik (Maximum likelihood): }E[f(\\boldsymbol X_{\\text{test}})] = \\boldsymbol \\phi(X_{\\text{test}})\\boldsymbol \\theta_{ml}\\\\\n",
    "&\\text{En Büyük Posteriyori (Maximum a posteriori): } E[f(\\boldsymbol X_{\\text{test}})] = \\boldsymbol \\phi(X_{\\text{test}})\\boldsymbol \\theta_{map}\\\\\n",
    "&\\text{Bayesyen: } p(f(\\boldsymbol X_{\\text{test}})) = \\mathcal N(f(\\boldsymbol X_{\\text{test}}) \\,|\\, \\boldsymbol \\phi(X_{\\text{test}}) \\boldsymbol\\theta_{\\text{mean}},\\, \\boldsymbol\\phi(X_{\\text{test}}) \\boldsymbol\\theta_{\\text{var}}  \\boldsymbol\\phi(X_{\\text{test}})^\\top)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kestirimler (ölçüm/gözlem gürültülerini yoksayarak)\n",
    "Phi_test = poli_oznitelikleri(Xtest, pol_der) # N x (K+1)\n",
    "\n",
    "# en büyük olabilirlik kestirimleri (sadece ortalama)\n",
    "m_mle_test = Phi_test.dot(theta_ml)\n",
    "\n",
    "# MAP kestirimleri (sadece ortalama)\n",
    "m_map_test = Phi_test.dot(theta_map)\n",
    "\n",
    "# kestirim dağılımı (Bayesyen Doğrusal Bağlanım, Bayesian linear regression)\n",
    "# ortalama kestirimi\n",
    "ortalama_bdb = Phi_test.dot(theta_ortalama)\n",
    "# varyans kestirimi\n",
    "kov_bdb =  Phi_test.dot(theta_var).dot(Phi_test.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posteriyor çizimi\n",
    "plt.figure()\n",
    "plt.plot(X, y, \"+\")\n",
    "plt.plot(Xtest, m_mle_test)\n",
    "plt.plot(Xtest, m_map_test)\n",
    "var_bdb = np.diag(kov_bdb)\n",
    "guven_sinir1 = np.sqrt(var_bdb).flatten()\n",
    "guven_sinir2 = 2.0*np.sqrt(var_bdb).flatten()\n",
    "guven_sinir3 = 2.0*np.sqrt(var_bdb + sigma).flatten()\n",
    "\n",
    "plt.fill_between(Xtest.flatten(), ortalama_bdb.flatten() + guven_sinir1, \n",
    "                 ortalama_bdb.flatten() - guven_sinir1, alpha = 0.1, color=\"k\")\n",
    "plt.fill_between(Xtest.flatten(), ortalama_bdb.flatten() + guven_sinir2, \n",
    "                 ortalama_bdb.flatten() - guven_sinir2, alpha = 0.1, color=\"k\")\n",
    "plt.fill_between(Xtest.flatten(), ortalama_bdb.flatten() + guven_sinir3, \n",
    "                 ortalama_bdb.flatten() - guven_sinir3, alpha = 0.1, color=\"k\")\n",
    "plt.legend([\"Eğitim Kümesi\", \"MLE (En büyük olabilirlik)\", \"MAP\", \"BDB\"])\n",
    "plt.xlabel('$x$');\n",
    "plt.ylabel('$y$');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
